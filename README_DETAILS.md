# ğŸš€ MATLAB to C++ Agentic Service - Detailed Documentation

A **native LangGraph-based** agentic system for converting MATLAB projects to C++ with intelligent analysis, planning, and iterative optimization using state-of-the-art language models. Built with **Function-First architecture** and **multi-turn optimization** capabilities.

## âœ¨ Features

- ğŸ§  **Native LangGraph Architecture**: Built from the ground up using LangGraph for true agentic workflows
- ğŸ”„ **Multi-Turn Optimization**: Iterative code improvement with intelligent quality assessment and feedback loops
- ğŸ“ **Multi-File Project Support**: Convert entire MATLAB projects with automatic dependency resolution and function call tree analysis
- ğŸ—ï¸ **Function-First Agent Design**: Specialized agents organized by function (analyzer, planner, generator, assessor, validator)
- ğŸ“Š **Comprehensive Quality Assessment**: Multi-dimensional code quality evaluation with detailed reports
- ğŸ¯ **Flexible Conversion Modes**: Support for different C++ standards and project structures
- ğŸ’» **Modern CLI Interface**: Clean command-line interface with rich configuration support
- âš™ï¸ **vLLM Integration**: Optimized for self-hosted vLLM with configurable LLM providers
- ğŸ“‚ **Organized Output**: Structured output with separate directories for code, reports, and debug information
- ğŸ”§ **Robust JSON Parsing**: Enhanced error handling for reliable LLM response processing
- ğŸ›ï¸ **Advanced State Management**: LangGraph-based state management with memory and performance tracking

## ğŸ“¦ Installation

### Prerequisites

Make sure you have [uv](https://docs.astral.sh/uv/) installed:

```bash
# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Project Setup

```bash
# Clone the repository
git clone <repository-url>
cd matlab2cpp_agentic_service

# Install dependencies using uv
uv sync

# Install in development mode
uv pip install -e .
```

### Dependencies

The project uses `uv` for dependency management. Key dependencies include:
- ğŸ“ `loguru` - Advanced logging
- ğŸ”§ `pydantic` - Data validation and configuration management
- âš™ï¸ `pyyaml` - YAML configuration file support
- ğŸ–±ï¸ `click` - CLI framework
- ğŸŒ `python-dotenv` - Environment variable management
- ğŸ¤– `langgraph` - Native graph-based agent workflows
- ğŸ”— `langchain-community` - LLM provider support
- ğŸŒ `httpx` - HTTP client for vLLM integration

## ğŸš€ Usage

### ğŸ”§ Quick Setup

1. **Configure your environment**:
   ```bash
   # Copy the template and customize
   cp examples/env_files/env.vllm.remote .env
   # Edit .env with your vLLM server settings
   ```

2. **Test your configuration**:
   ```bash
   uv run python -m matlab2cpp_agentic_service.cli test-llm
   ```

### ğŸ’» Command Line Interface

**Using the native LangGraph CLI**:

```bash
# ğŸ”„ Convert a MATLAB project to C++
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project

# ğŸ” Analyze a MATLAB project without conversion
uv run python -m matlab2cpp_agentic_service.cli analyze examples/matlab_samples/arma_filter.m --detailed

# âœ… Validate a converted C++ project
uv run python -m matlab2cpp_agentic_service.cli validate output/my_project

# ğŸ§ª Test LLM connection
uv run python -m matlab2cpp_agentic_service.cli test-llm

# ğŸ“š Show available examples
uv run python -m matlab2cpp_agentic_service.cli examples
```

### âš™ï¸ Configuration Options

**Using different configurations**:

```bash
# Use specific .env file
uv run python -m matlab2cpp_agentic_service.cli --env examples/env_files/env.vllm.remote convert examples/matlab_samples/arma_filter.m my_project

# Use YAML config file
uv run python -m matlab2cpp_agentic_service.cli --config config/default_config.yaml convert examples/matlab_samples/arma_filter.m my_project

# Verbose output with custom .env
uv run python -m matlab2cpp_agentic_service.cli --verbose --env examples/env_files/env.development convert examples/matlab_samples/arma_filter.m my_project
```

### ğŸ¯ Advanced Conversion Options

```bash
# Convert with custom parameters
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project \
  --output-dir ./cpp_output \
  --max-turns 3 \
  --target-quality 8.0 \
  --cpp-standard C++20

# Multi-file MATLAB project conversion
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/skeleton_vessel my_multi_file_project \
  --max-turns 2 \
  --target-quality 7.5

# Disable optimization (max-turns=0)
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project \
  --max-turns 0

# JSON output for automation
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project --json-output
```

### ğŸ Programmatic Usage

```python
from matlab2cpp_agentic_service.core.orchestrators.native_langgraph_orchestrator import NativeLangGraphMATLAB2CPPOrchestrator
from matlab2cpp_agentic_service.infrastructure.state.conversion_state import ConversionRequest

# ğŸ—ï¸ Initialize native LangGraph orchestrator
orchestrator = NativeLangGraphMATLAB2CPPOrchestrator()

# ğŸ“‹ Create conversion request for single file
request = ConversionRequest(
    matlab_path=Path("examples/matlab_samples/arma_filter.m"),
    project_name="my_cpp_project",
    output_dir=Path("./output"),
    max_optimization_turns=2,
    target_quality_score=7.0,
    cpp_standard="C++17"
)

# ğŸ“‹ Create conversion request for multi-file project
multi_file_request = ConversionRequest(
    matlab_path=Path("examples/matlab_samples/skeleton_vessel"),  # Directory path
    project_name="my_multi_file_project",
    output_dir=Path("./output"),
    max_optimization_turns=3,
    target_quality_score=8.0
)

# ğŸš€ Convert project
result = orchestrator.convert_project(request)

if result.status == "completed":
    print(f"âœ… Conversion successful! Quality score: {result.final_score}/10")
    print(f"ğŸ“ Generated files: {result.generated_files}")
    print(f"ğŸ“‹ Assessment reports: {result.assessment_reports}")
    print(f"ğŸ”„ Optimization turns used: {result.improvement_turns}")
else:
    print(f"âŒ Conversion failed: {result.error_message}")
```

## ğŸ—ï¸ Architecture

The system uses a **native LangGraph architecture** with Function-First agent organization:

### ğŸ”§ Core Components

- ğŸ¯ **NativeLangGraphMATLAB2CPPOrchestrator**: Main orchestrator using LangGraph workflows
- ğŸ” **MATLAB Analyzer Agents**: Analyze MATLAB code structure, content, and multi-file dependencies
- ğŸ“‹ **Conversion Planner Agents**: Create comprehensive C++ conversion plans with project structure planning
- âš¡ **C++ Generator Agents**: Generate optimized C++ code for both single and multi-file projects
- ğŸ“Š **Quality Assessor Agents**: Evaluate code quality with multi-dimensional assessment
- âœ… **Validator Agents**: Validate converted C++ projects
- ğŸ”§ **LangGraph Tools**: Specialized tools for LLM interactions with centralized prompts

### ğŸ“ Function-First Project Structure

```
matlab2cpp_agentic_service/
â”œâ”€â”€ ğŸ“„ pyproject.toml              # uv project configuration
â”œâ”€â”€ ğŸ“„ README.md                   # This file
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md        # Detailed project structure documentation
â”œâ”€â”€ ğŸ“‚ config/                     # Configuration files
â”‚   â””â”€â”€ default_config.yaml
â”œâ”€â”€ ğŸ“‚ examples/                   # Example files and samples
â”‚   â”œâ”€â”€ ğŸ“ env_files/              # Example .env configurations
â”‚   â”‚   â”œâ”€â”€ env.vllm.local         # Local vLLM server config
â”‚   â”‚   â”œâ”€â”€ env.vllm.remote        # Remote vLLM server config
â”‚   â”‚   â”œâ”€â”€ env.openai             # OpenAI API config
â”‚   â”‚   â””â”€â”€ env.development        # Development mode config
â”‚   â””â”€â”€ ğŸ“ matlab_samples/         # Example MATLAB projects
â”‚       â”œâ”€â”€ arma_filter.m          # Single-file example
â”‚       â””â”€â”€ skeleton_vessel/       # Multi-file project example
â”œâ”€â”€ ğŸ“‚ src/matlab2cpp_agentic_service/
â”‚   â”œâ”€â”€ ğŸ“ cli/                    # Command-line interface
â”‚   â”‚   â”œâ”€â”€ run.py                 # Main CLI entry point
â”‚   â”‚   â””â”€â”€ __main__.py            # CLI module entry point
â”‚   â”œâ”€â”€ ğŸ“ core/                   # Core business logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“ agents/             # Function-First agent organization
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ analyzer/       # MATLAB analysis agents
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ langgraph/  # Native LangGraph agents
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ legacy/     # Legacy agents (backward compatibility)
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ assessor/       # Quality assessment agents
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ langgraph/  # Native LangGraph assessors
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ base/           # Base agent classes and utilities
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ agent_registry.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ langgraph_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ memory_manager.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ performance_monitor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ generator/      # C++ code generation agents
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ langgraph/  # Native LangGraph generators
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ planner/        # Conversion planning agents
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ langgraph/  # Native LangGraph planners
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ validator/      # Code validation agents
â”‚   â”‚   â”‚       â””â”€â”€ ğŸ“ langgraph/  # Native LangGraph validators
â”‚   â”‚   â”œâ”€â”€ ğŸ“ orchestrators/      # Workflow orchestration
â”‚   â”‚   â”‚   â””â”€â”€ native_langgraph_orchestrator.py
â”‚   â”‚   â””â”€â”€ ğŸ“ workflows/          # LangGraph workflows
â”‚   â”‚       â””â”€â”€ native_langgraph_workflow.py
â”‚   â”œâ”€â”€ ğŸ“ infrastructure/         # Infrastructure components
â”‚   â”‚   â”œâ”€â”€ ğŸ“ state/              # State management
â”‚   â”‚   â”‚   â”œâ”€â”€ conversion_state.py
â”‚   â”‚   â”‚   â”œâ”€â”€ shared_memory.py
â”‚   â”‚   â”‚   â””â”€â”€ state_validator.py
â”‚   â”‚   â””â”€â”€ ğŸ“ tools/              # LangGraph tools and utilities
â”‚   â”‚       â”œâ”€â”€ langgraph_tools.py # Centralized LangGraph tools with prompts
â”‚   â”‚       â”œâ”€â”€ llm_client.py      # LLM client for vLLM integration
â”‚   â”‚       â””â”€â”€ matlab_parser.py   # MATLAB parsing utilities
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Data models and schemas
â”‚   â”œâ”€â”€ ğŸ“ templates/              # Code templates
â”‚   â””â”€â”€ ğŸ“ utils/                  # Utility functions
â”œâ”€â”€ ğŸ“ output/                     # Generated C++ projects (organized by project)
â”‚   â”œâ”€â”€ project_name/
â”‚   â”‚   â”œâ”€â”€ generated_code/        # C++ files (.h, .cpp)
â”‚   â”‚   â”œâ”€â”€ reports/              # Assessment reports (.md)
â”‚   â”‚   â””â”€â”€ debug/                # Debug information (.json, .txt)
â”œâ”€â”€ ğŸ“ tests/                      # Test suite
â”‚   â”œâ”€â”€ ğŸ“ fixtures/              # Test fixtures
â”‚   â”œâ”€â”€ ğŸ“ integration/           # Integration tests
â”‚   â””â”€â”€ ğŸ“ unit/                  # Unit tests
â””â”€â”€ ğŸ“„ uv.lock                     # Dependency lock file
```

## âš™ï¸ Configuration

The system supports multiple LLM providers and can be configured using `.env` files or environment variables.

### ğŸ”§ Environment Configuration (.env)

**Recommended approach**: Use `.env` files for easy configuration management.

1. **Copy the template**:
   ```bash
   cp examples/env_files/env.vllm.remote .env
   ```

2. **Edit the `.env` file** with your settings:
   ```bash
   # For remote vLLM server
   LLM_PROVIDER=vllm
   VLLM_ENDPOINT=http://192.168.6.10:8002
   VLLM_MODEL_NAME=Qwen/Qwen3-32B-FP8
   VLLM_API_KEY=dummy_key
   ```

3. **Use example configurations**:
   ```bash
   # For local vLLM
   cp examples/env_files/env.vllm.local .env
   
   # For remote vLLM
   cp examples/env_files/env.vllm.remote .env
   
   # For OpenAI
   cp examples/env_files/env.openai .env
   
   # For development
   cp examples/env_files/env.development .env
   ```

### ğŸŒ Environment Variables

Alternatively, set environment variables directly:

```bash
# ğŸš€ For vLLM (recommended)
export VLLM_ENDPOINT="http://your-vllm-server:8002"
export VLLM_MODEL_NAME="Qwen/Qwen3-32B-FP8"
export LLM_PROVIDER="vllm"
export LLM_API_KEY="your-api-key"

# ğŸ¤– For OpenAI
export OPENAI_API_KEY="your-openai-api-key"
export LLM_PROVIDER="openai"
export LLM_MODEL="gpt-4"
```

### ğŸ“‹ Available Configuration Options

| Variable | Description | Default | Example |
|----------|-------------|---------|---------|
| `LLM_PROVIDER` | LLM provider (vllm, openai) | `vllm` | `vllm` |
| `VLLM_ENDPOINT` | vLLM server endpoint | `http://localhost:8000` | `http://192.168.6.10:8002` |
| `VLLM_MODEL_NAME` | vLLM model name | `Qwen/Qwen3-32B-FP8` | `Qwen/Qwen3-32B-FP8` |
| `OPENAI_API_KEY` | OpenAI API key | - | `sk-...` |
| `OPENAI_MODEL` | OpenAI model | `gpt-4` | `gpt-4-turbo` |
| `LLM_TIMEOUT` | Request timeout (seconds) | `1200` | `300` |
| `LLM_MAX_TOKENS` | Max tokens per request | `8000` | `4000` |
| `LLM_TEMPERATURE` | Response temperature | `0.1` | `0.2` |
| `DEFAULT_OUTPUT_DIR` | Output directory | `./output` | `./cpp_projects` |
| `DEFAULT_CPP_STANDARD` | C++ standard | `C++17` | `C++20` |
| `DEFAULT_MAX_TURNS` | Max optimization turns | `2` | `3` |
| `DEFAULT_TARGET_QUALITY` | Target quality score | `7.0` | `8.5` |
| `LOG_LEVEL` | Log level | `INFO` | `DEBUG` |

## ğŸ”„ Conversion Process

### Native LangGraph Workflow

The system uses a **native LangGraph workflow** with the following stages:

1. ğŸ” **Analysis**: MATLAB content is analyzed using LangGraph-native agents
2. ğŸ“‹ **Planning**: A comprehensive C++ conversion plan is created with architecture recommendations
3. âš¡ **Generation**: Initial C++ code is generated following the conversion plan
4. ğŸ“Š **Assessment**: Code quality is evaluated across multiple dimensions
5. ğŸ”„ **Optimization Check**: Intelligent decision on whether to continue optimization
6. âœ… **Validation**: Final code is validated for compilation and functionality

### Multi-Turn Optimization

The system supports **intelligent multi-turn optimization**:

- **Turn 0**: Initial generation
- **Turn 1-N**: Optimization turns based on quality assessment
- **Early Termination**: Stops if quality is declining or target is met
- **Max Turns Control**: Configurable maximum optimization turns (including `max-turns=0`)

### Multi-File Projects

1. ğŸ” **Function Call Detection**: Analyzes all `.m` files to build dependency graphs
2. ğŸ“‹ **Project Structure Planning**: Determines optimal C++ file organization
3. ğŸ—ï¸ **Compilation Order Planning**: Uses topological sorting for correct compilation sequence
4. âš¡ **Multi-File Generation**: Generates coordinated C++ files with proper includes
5. ğŸ“Š **Project-Level Assessment**: Evaluates the entire project for quality
6. ğŸ”„ **Iterative Optimization**: Improves code across multiple turns if needed

## ğŸ“Š Quality Assessment

The system provides comprehensive quality assessment including:
- ğŸ¯ **Overall Quality**: Combined score from all assessment dimensions
- âš¡ **Performance**: Optimization opportunities and efficiency analysis
- ğŸ›¡ï¸ **Error Handling**: Robustness and edge case coverage
- ğŸ¨ **Code Style**: Syntax, formatting, and best practices compliance
- ğŸ› ï¸ **Maintainability**: Code structure, documentation, and readability
- âœ… **Functional Equivalence**: Correctness compared to original MATLAB
- ğŸ“‹ **Completeness**: Coverage of all MATLAB functionality

**Quality Score**: Overall score from 0-10 with detailed breakdown and improvement recommendations.

## ğŸ› ï¸ Development

### Quick Start

```bash
# ğŸ”§ Install development dependencies
uv sync --dev

# ğŸš€ Test LLM connection
uv run python -m matlab2cpp_agentic_service.cli test-llm

# ğŸ§ª Test single file conversion
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m test_project

# ğŸ§ª Test multi-file conversion
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/skeleton_vessel test_multi_project
```

### Development Workflow

```bash
# ğŸš€ Run with development configuration
uv run python -m matlab2cpp_agentic_service.cli --env examples/env_files/env.development convert examples/matlab_samples/arma_filter.m dev_test

# ğŸ“¦ Add new dependencies
uv add package-name

# ğŸ”„ Update dependencies
uv sync

# ğŸ§¹ Clean virtual environment
uv sync --reinstall
```

### Testing

```bash
# Run all tests
uv run pytest tests/

# Run integration tests
uv run pytest tests/integration/

# Run specific test
uv run pytest tests/integration/test_multi_file_conversion.py
```

## ğŸ“š Examples

See the `examples/` directory for sample MATLAB projects and their C++ conversions in the `output/` directory.

### ğŸ¯ Quick Examples

**Single-File Conversion**:
```bash
# Setup configuration
cp examples/env_files/env.vllm.remote .env

# Convert the ARMA filter example
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m arma_filter_cpp

# View results
ls output/arma_filter_cpp/
```

**Multi-File Project Conversion**:
```bash
# Convert entire MATLAB project with multiple files
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/skeleton_vessel skeleton_vessel_cpp \
  --max-turns 2

# View organized results
ls output/skeleton_vessel_cpp/
```

### ğŸ“‹ Example Output Structure

**Single-File Projects**:
```
output/project_name/
â”œâ”€â”€ generated_code/
â”‚   â”œâ”€â”€ v1.h                    # Header file
â”‚   â””â”€â”€ v1.cpp                  # Implementation file
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ v1_assessment_report.md # Quality analysis
â””â”€â”€ debug/                      # Debug information
```

**Multi-File Projects**:
```
output/project_name/
â”œâ”€â”€ generated_code/
â”‚   â”œâ”€â”€ v1_function1.h/.cpp     # Header/implementation pairs
â”‚   â”œâ”€â”€ v1_function2.h/.cpp
â”‚   â”œâ”€â”€ v1_main.cpp             # Main entry point
â”‚   â””â”€â”€ v1_compilation_instructions.md
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ v1_assessment_report.md # Project-level quality analysis
â””â”€â”€ debug/                      # Debug information
```

## ğŸ†• Recent Improvements

### Version 0.2.0 - Native LangGraph Architecture
- âœ… **Native LangGraph Implementation**: Complete rewrite using LangGraph for true agentic workflows
- âœ… **Function-First Agent Organization**: Agents organized by function rather than framework type
- âœ… **Enhanced State Management**: LangGraph-based state management with memory and performance tracking
- âœ… **Robust JSON Parsing**: Enhanced error handling with centralized JSON cleaning utilities
- âœ… **Multi-Turn Optimization**: Intelligent optimization with early termination and declining quality detection
- âœ… **Clean Project Structure**: Organized, professional project structure with comprehensive documentation
- âœ… **Improved CLI**: Modern CLI with better error handling and configuration management
- âœ… **vLLM Integration**: Optimized for self-hosted vLLM with reliable connection handling

### Key Features
- ğŸ§  **Native LangGraph**: Built from the ground up using LangGraph for full framework utilization
- ğŸ”„ **Multi-Turn Optimization**: Intelligent iterative improvement with quality-based decisions
- ğŸ“ **Multi-File Support**: Complete support for MATLAB projects with multiple `.m` files
- ğŸ—ï¸ **Function-First Architecture**: Clear separation of concerns with specialized agents
- ğŸ“Š **Quality Assessment**: Multi-dimensional quality evaluation with detailed reports
- ğŸ¯ **Flexible Configuration**: Support for multiple LLM providers and configuration methods

## ğŸ”§ Troubleshooting

### Common Issues

**LLM Connection Failed**:
```bash
# Test your configuration
uv run python -m matlab2cpp_agentic_service.cli test-llm

# Check your .env file
cat .env

# Try different configuration
cp examples/env_files/env.vllm.local .env
```

**Conversion Takes Too Long**:
```bash
# Use development configuration for faster processing
cp examples/env_files/env.development .env

# Reduce optimization turns
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project --max-turns 1
```

**Low Quality Scores**:
```bash
# Increase optimization turns
uv run python -m matlab2cpp_agentic_service.cli convert examples/matlab_samples/arma_filter.m my_project --max-turns 3 --target-quality 8.5

# Enable verbose output for debugging
uv run python -m matlab2cpp_agentic_service.cli --verbose convert examples/matlab_samples/arma_filter.m my_project
```

**Multi-File Project Issues**:
```bash
# Check if MATLAB project directory contains .m files
ls examples/matlab_samples/skeleton_vessel/

# Check organized output structure
ls output/my_project/
```

### Getting Help

1. **Check the logs**: Enable verbose mode with `--verbose` flag
2. **Test LLM connection**: Run `uv run python -m matlab2cpp_agentic_service.cli test-llm`
3. **Try example configurations**: Use pre-configured .env files in `examples/env_files/`
4. **Review assessment reports**: Check generated `.md` files in `output/` directory
5. **Check project structure**: See `PROJECT_STRUCTURE.md` for detailed architecture

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

<div align="center">

**ğŸš€ Built with â¤ï¸ using native LangGraph architecture and modern Python tooling**

[![uv](https://img.shields.io/badge/uv-0.2.0-blue.svg)](https://docs.astral.sh/uv/)
[![Python](https://img.shields.io/badge/Python-3.12+-green.svg)](https://python.org)
[![LangGraph](https://img.shields.io/badge/LangGraph-Native-orange.svg)](https://langchain.com/langgraph)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**Transform MATLAB code into production-ready C++ with native LangGraph agents, multi-file project support, and intelligent multi-turn optimization**

</div>
