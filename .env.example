# ==============================================
# MATLAB2C++ AGENTIC SERVICE - ENVIRONMENT CONFIGURATION
# ==============================================

# ==============================================
# GENERAL MODEL CONFIGURATION (for reasoning agents)
# Used by: MATLAB Analyzer, Conversion Planner, Quality Assessor, Project Manager
# ==============================================

# General model provider (vllm, openai, anthropic, etc.)
GENERAL_MODEL_PROVIDER=vllm

# General model name (your reasoning model - examples: llama-3-8b-instruct, gpt-4-turbo, etc.)
GENERAL_MODEL=your_reasoning_model_name

# General model API configuration
GENERAL_MODEL_API_KEY=your_api_key_here
GENERAL_MODEL_TEMPERATURE=0.1
GENERAL_MODEL_MAX_TOKENS=4000
GENERAL_MODEL_TIMEOUT=300

# General model vLLM configuration
GENERAL_VLLM_ENDPOINT=http://localhost:8000/v1
GENERAL_VLLM_MODEL_NAME=your_reasoning_model_name
GENERAL_BASE_URL=http://localhost:8000/v1

# ==============================================
# CODING MODEL CONFIGURATION (for C++ generation)
# Used by: C++ Generator only
# ==============================================

# Coding model provider (vllm, openai, anthropic, etc.)
CODING_MODEL_PROVIDER=vllm

# Coding model name (direct model without reasoning - examples: Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8, gpt-4-turbo, etc.)
CODING_MODEL=Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8

# Coding model API configuration
CODING_MODEL_API_KEY=your_api_key_here
CODING_MODEL_TEMPERATURE=0.1
CODING_MODEL_MAX_TOKENS=4000
CODING_MODEL_TIMEOUT=300

# Coding model vLLM configuration
CODING_VLLM_ENDPOINT=http://192.168.6.19:8011/v1
CODING_VLLM_MODEL_NAME=Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8
CODING_BASE_URL=http://192.168.6.19:8011/v1

# ==============================================
# EXAMPLE CONFIGURATIONS
# ==============================================

# Example 1: Local vLLM Setup
# GENERAL_MODEL_PROVIDER=vllm
# GENERAL_MODEL=llama-3-8b-instruct
# GENERAL_VLLM_ENDPOINT=http://localhost:8000/v1
# CODING_MODEL_PROVIDER=vllm
# CODING_MODEL=Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8
# CODING_VLLM_ENDPOINT=http://192.168.6.19:8011/v1

# Example 2: OpenAI Setup
# GENERAL_MODEL_PROVIDER=openai
# GENERAL_MODEL=gpt-4-turbo
# GENERAL_MODEL_API_KEY=your_openai_api_key
# CODING_MODEL_PROVIDER=openai
# CODING_MODEL=gpt-4-turbo
# CODING_MODEL_API_KEY=your_openai_api_key

# Example 3: Mixed Setup (Reasoning on vLLM, Coding on OpenAI)
# GENERAL_MODEL_PROVIDER=vllm
# GENERAL_MODEL=llama-3-8b-instruct
# GENERAL_VLLM_ENDPOINT=http://localhost:8000/v1
# CODING_MODEL_PROVIDER=openai
# CODING_MODEL=gpt-4-turbo
# CODING_MODEL_API_KEY=your_openai_api_key

# ==============================================
# CONVERSION SETTINGS
# ==============================================

# Default conversion settings
DEFAULT_MAX_TURNS=3
DEFAULT_TARGET_QUALITY=8.0
INCLUDE_OPTIMIZATION=true
GENERATE_TESTS=true
CREATE_DOCUMENTATION=true

# ==============================================
# LOGGING CONFIGURATION
# ==============================================

LOG_LEVEL=INFO
ENABLE_CONSOLE_LOGGING=true

# ==============================================
# PROJECT SETTINGS
# ==============================================

DEFAULT_OUTPUT_DIR=output
DEV_MODE=false
ENABLE_PROFILING=false
